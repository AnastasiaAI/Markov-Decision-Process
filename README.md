# Markov-Decision-Process
MDP: Policy and Value Iteration

ECE183DA (Winter 2020)
Design of Robotic Systems I
Prof. Ankur Mehta
mehtank@ucla.edu
Problem set 1

Author: Anastasia Sukhorebraya-Beck
UID: 304 854 296

1.1 Objectives
The goal of this lab is to explore Markov Decision Processes (MDPs) to control a simple discretized robot.
Here I develop and implement a model of the robot behavior and use it to optimally accomplish a prescribed task.

0(a). Collaborated with: n/a
0(b). Consulted resources:
1) Python MDPs: https://pymdptoolbox.readthedocs.io/en/latest/
2) Rat in a maze: https://www.geeksforgeeks.org/rat-in-a-maze-backtracking-2/



1(a) The size of the state space N_s is |N_s| = L*H =  number of possible states = #(states) = len(grid) * height(grid)
1(b) The size of the action space N_a = 5
